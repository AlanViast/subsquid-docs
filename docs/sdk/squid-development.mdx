---
sidebar_position: 30
title: Development flow
description: A general approach to squid development
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

This page is a definitive end-to-end guide into practical squid development. It uses templates and `sqd` [scripts](https://github.com/subsquid/squid-sdk/tree/master/util/commands) to simplify the process. Check out [Squid from scratch](/sdk/squid-from-scratch) for a more educational barebones approach.

## Prepare the environment

- Node v16.x or newer
- Git
- [Squid CLI](/squid-cli/installation)
- Docker (if your squid will store its data to PostgreSQL)

See also the [Environment set up](/sdk/resources/development-environment-set-up) page.

## Understand your technical requirements

Consider your business requirements and find out

1. How the data should be delivered. Options:
   - [PostgreSQL](/sdk/resources/persisting-data/typeorm) with an optional [GraphQL API](/sdk/reference/graphql-server) - can be real-time
   - [file-based dataset](/sdk/resources/persisting-data/file) - local or on S3
   - [Google BigQuery](/sdk/resources/persisting-data/bigquery/)
2. What data should be delivered
3. What are the technologies powering the blockchain(s) in question. Supported options:
   - Ethereum Virtual Machine (EVM) chains like [Ethereum](https://ethereum.org) - [supported networks](/subsquid-network/reference/evm-networks)
   - [Substrate](https://substrate.io)-powered chains like [Polkadot](https://polkadot.network) and [Kusama](https://kusama.network) - [supported networks](/subsquid-network/reference/substrate-networks)

   Note that you can use Subsquid via [RPC ingestion](/dead) even if your network is not listed.
4. What exact data should be retrieved from blockchain(s)
5. Whether you need to mix in any [off-chain data](/sdk/resources/external-api)

#### Example requirements

<details><summary>DEX analytics on Polygon</summary>

Suppose you want to train a prototype ML model on all trades done on Uniswap Polygon since the v3 upgrade.

1. A delay of a few hours typically won't matter for training, so you may want to deliver the data as files for easier handling.
2. The output could be a simple list of swaps, listing pair, direction and token amounts for each.
3. Polygon is an EVM chain.
4. All the required data is contained within `Swap` events emitted by the pair pool contracts. Uniswap deploys these [dynamically](/sdk/resources/evm/factory-contracts), so you will also have to capture `PoolCreated` events from the factory contract to know which `Swap` events are coming from Uniswap and map them to pairs.
5. No off-chain data will be necessary for this task.

</details>

<details><summary>NFT ownership on Ethereum</summary>

Suppose you want to make a website that shows the image and ownership history for ERC721 NFTs from a certain Polygon contract.

1. For this application it makes sense to deliver a GraphQL API.
2. Output data might have `Token`, `Owner` and `Transfer` [entities](/sdk/reference/openreader/queries), with e.g. `Token` supplying all the fields necessary to show ownership history and the image.
3. Ethereum is an EVM chain.
4. Data on token mints and ownership history can be derived from `Transfer(address,address,uint256)` EVM event logs emitted by the contract. To render images, you will also need token metadata URLs that are only available by [querying the contract state](/sdk/reference/typegen/state-queries) with the `tokenURI(uint256)` function.
5. You'll need to retrieve the off-chain token metadata (usually from IPFS).

</details>

<details><summary>Kusama transfers BigQuery dataset</summary>

Suppose you want to create a BigQuery dataset with Kusama native tokens transfers.

1. The delivery format is BigQuery.
2. A single table with `from`, `to` and `amount` columns may suffice.
3. Kusama is a Substrate chain.
4. The required data is available from `Transfer` events emitted by the `Balances` pallet. Take a look at our [Substrate data sourcing miniguide](/sdk/resources/substrate/data-sourcing-miniguide) for more info on how to figure out which pallets, events and calls are necessary for your task.
5. No off-chain data will be necessary for this task.

</details>

## Start from a template {#templates}

Although it is possible to [compose a squid from individual packages](/sdk/squid-from-scratch), in practice it is usually easier to start from a template.

```mdx-code-block
<Tabs>
<TabItem value="evm" label="EVM">
<details><summary>Templates for the PostgreSQL+GraphQL data destination</summary>
```

- A minimal template intended for developing EVM squids. Indexes ETH burns.
  ```bash
  sqd init my-squid-name -t evm
  ```
- Classic [example Subgraph](https://github.com/graphprotocol/example-subgraph) after a [migration](/sdk/resources/migrate/migrate-subgraph) to Subsquid.
  ```bash
  sqd init my-squid-name -t gravatar
  ```
- A template showing how to [combine data from multiple chains](/sdk/resources/multichain). Indexes USDC transfers on Ethereum and Binance.
  ```bash
  sqd init my-squid-name -t multichain
  ```

```mdx-code-block
</details>
<details><summary>Templates for storing data in files</summary>
```

- USDC transfers -> local CSV
  ```bash
  sqd init my-squid-name -t https://github.com/subsquid-labs/file-store-csv-example
  ```
- USDC transfers -> local Parquet
  ```bash
  sqd init my-squid-name -t https://github.com/subsquid-labs/file-store-parquet-example
  ```
- USDC transfers -> CSV on S3
  ```bash
  sqd init my-squid-name -t https://github.com/subsquid-labs/file-store-s3-example
  ```

```mdx-code-block
</details>
</TabItem>
<TabItem value="substrate" label="Substrate">
<details><summary>Templates for the PostgreSQL+GraphQL data destination</summary>
```

- Native events emitted by Substrate-based chains
  ```bash
  sqd init my-squid-name -t substrate
  ```
- ink! smart contracts
  ```bash
  sqd init my-squid-name -t ink
  ```
- Frontier EVM contracts on Astar and Moonbeam
  ```bash
  sqd init my-squid-name -t frontier-evm
  ```

```mdx-code-block
</details>
</TabItem>
</Tabs>
```

After retrieving the template of choice install its dependencies:
```bash
cd my-squid-name
npm ci
```
Test the template locally. The procedure varies depending on the data sink:

```mdx-code-block
<Tabs>
<TabItem value="typeorm" label="PostgreSQL+GraphQL">
```
1. Launch a PostgreSQL container with `sqd up`
2. Start the squid processor with `sqd process`. You should see output that contains lines like these ones:
   ```bash
   04:11:24 INFO  sqd:processor processing blocks from 6000000
   04:11:24 INFO  sqd:processor using archive data source
   04:11:24 INFO  sqd:processor prometheus metrics are served at port 45829
   04:11:27 INFO  sqd:processor 6051219 / 18079056, rate: 16781 blocks/sec, mapping: 770 blocks/sec, 544 items/sec, eta: 12m
   ```
3. Start the GraphQL server by running `sqd serve` in a separate terminal, then visit the [GraphiQL console](http://localhost:4350/graphql) to verify that the GraphQL API is up.

When done, shut down and erase your database with `sqd down`.

```mdx-code-block
</TabItem>
<TabItem value="file-store" label="filesystem dataset">
```

1. (for the S3 template only) Set the credentials and prepare a bucket for your data as described in the [template README](https://github.com/subsquid-labs/file-store-s3-example/blob/main/README.md).
2. Start the squid processor with `sqd process`. You should see output that contains lines like these ones:
   ```bash
   04:11:24 INFO  sqd:processor processing blocks from 6000000
   04:11:24 INFO  sqd:processor using archive data source
   04:11:24 INFO  sqd:processor prometheus metrics are served at port 45829
   04:11:27 INFO  sqd:processor 6051219 / 18079056, rate: 16781 blocks/sec, mapping: 770 blocks/sec, 544 items/sec, eta: 12m
   ```
   You should see a `./data` folder populated with indexer data appear in a bit. A local folder looks like this:
   ```bash
   $ tree ./data/
   ./data/
   ├── 0000000000-0007242369
   │   └── transfers.tsv
   ├── 0007242370-0007638609
   │   └── transfers.tsv
   ...
   └── status.txt
   ```

```mdx-code-block
</TabItem>
</Tabs>
```
:::info
To make local runs more convenient squid templates define additional `sqd` commands at `commands.json`. All of `sqd` commands used here are such extras. Take a look at the contents of this file to learn more about how your template works [under the hood](/sdk/squid-from-scratch).
:::

## Regenerate the task-specific utilities {#typegen}

```mdx-code-block
<Tabs>
<TabItem value="evm" label="EVM">
```
Retrieve JSON ABIs for all contracts of interest (e.g. from Etherscan), taking care to get implementation ABIs for [proxies](/sdk/resources/evm/proxy-contracts) where appropriate. Assuming that you saved the ABI files to `./abi`, you can then regenerate the utilities with
```bash
sqd typegen
```
Or if you would like the tool to retrieve the ABI from Etherscan in your stead, you can run e.g.
```bash
npx squid-evm-typegen \
  src/abi \
  0xdAC17F958D2ee523a2206206994597C13D831ec7#usdt
```
The utility classes will become available at `src/abi`.

[Full reference for EVM typegen](/dead).

```mdx-code-block
</TabItem>
<TabItem value="substrate" label="Substrate">
```
Follow the respective reference configuration pages of each typegen tool:

* [Substrate typegen configuration](/dead)
* [ink! typegen configuration](/dead)

```mdx-code-block
<details><summary>A tip for `frontier-evm` squids</summary>
```
These squids use both Substrate typegen _and_ EVM typegen. To generate all the required utilities, [configure the Substrate part](/dead), then save all relevant JSON ABIs to `./abi`, then run
```bash
sqd typegen
```

```mdx-code-block
</details>
</TabItem>
</Tabs>
````

## Configure the data requests

Data requests are [customarily](/sdk/reference/layout) defined at `src/processor.ts`. The details depend on the network type:

```mdx-code-block
<Tabs>
<TabItem value="evm" label="EVM">
```
Edit the definition of `const processor` to

1. Use a [data source](/sdk/reference/processors/evm-batch/general/#set-data-source) appropriate for your chain and task.
   - If you're building a real-time API, use both RPC and a [Subsquid Network dataset](/subsquid-network/reference/evm-networks) whenever possible.
   - If you're using RPC as one of your data sources, make sure to [set the number of finality confirmations](/sdk/reference/processors/evm-batch/general/#set-finality-confirmation) so that [hot blocks ingestion](/sdk/resources/unfinalized-blocks) works properly.
2. Request all [event logs](/sdk/reference/processors/evm-batch/logs/), [transactions](/sdk/reference/processors/evm-batch/transactions/), [execution traces](/sdk/reference/processors/evm-batch/traces) and [state diffs](/sdk/reference/processors/evm-batch/state-diffs/) that your task requires, with any necessary related data (e.g. parent transactions for event logs).

3. [Select all data fields](/sdk/reference/processors/evm-batch/field-selection) necessary for your task (e.g. `gasUsed` for transactions).

See [reference documentation](/sdk/reference/processors/evm-batch) for more info and [processor configuration showcase](/sdk/examples/#evm-showcase) for a representative set of examples.

```mdx-code-block
</TabItem>
<TabItem value="substrate" label="Substrate">
```

Edit the definition of `const processor` to

1. Use a [data source](/sdk/reference/processors/subtrate-batch/general/#set-data-source) appropriate for your chain and task
   - Use a [Subsquid Network dataset](/subsquid-network/reference/evm-networks) whenever it is available. RPC is still required in this case.
   - For networks without a dataset use just the RPC.

2. Request all [events](/sdk/reference/processors/subtrate-batch/data-requests/#events) and [calls](/sdk/reference/processors/subtrate-batch/data-requests/#calls) that your task requires, with any necessary related data (e.g. parent extrinsics).

3. If your squid indexes any of the following:
   - an [ink! contract](/sdk/resources/substrate/ink)
   - an EVM contract running on the [Frontier EVM pallet](/sdk/resources/substrate/frontier-evm)
   - [Gear messages](/sdk/resources/substrate/gear)

   then you can use some of the [specialized data requesting methods](/dead) to retrieve data more selectively.

4. [Select all data fields](/sdk/reference/processors/subtrate-batch/field-selection) necessary for your task (e.g. `fee` for extrinsics).

See [reference documentation](/sdk/reference/processors/subtrate-batch) for more info. Processor config examples can be found in the tutorials:

* [general Substrate](/sdk/tutorials/substrate)

* [ink!](/sdk/tutorials/ink)

* [Frontier EVM](/sdk/tutorials/frontier-evm)

```mdx-code-block
</TabItem>
</Tabs>
```


```mdx-code-block
<Tabs>
<TabItem value="evm" label="EVM">
```
```mdx-code-block
</TabItem>
<TabItem value="substrate" label="Substrate">
```
```mdx-code-block
</TabItem>
</Tabs>
```


